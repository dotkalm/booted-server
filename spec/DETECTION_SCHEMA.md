# Detection JSON Schema Documentation

This document describes the structure and meaning of values in detection JSON files (e.g., `one_detection.json`). These files are generated by the car wheel detection API and contain all the information needed to overlay 3D assets on detected wheels using Three.js.

## Coordinate Systems

### Image Coordinates (Pixels)
- **Origin**: Top-left corner of the image
- **X-axis**: Increases rightward
- **Y-axis**: Increases downward
- Units are in pixels

### Normalized Coordinates (for Three.js)
- **Origin**: Center of the image
- **Range**: [-1, 1] for both X and Y
- **X-axis**: -1 = left edge, +1 = right edge
- **Y-axis**: -1 = bottom, +1 = top (flipped from image coordinates)
- **Z-axis**: Estimated depth, larger values = closer to camera

### 3D World Coordinates (Three.js Convention)
- **X-axis (Right)**: Points to the right
- **Y-axis (Up)**: Points upward
- **Z-axis (Forward)**: Points toward the camera (out of the screen)

---

## Top-Level Structure

```json
{
  "source": "one.jpg",           // Source image filename
  "image_dimensions": {...},     // Image size in pixels
  "total_cars": 1,               // Number of cars detected
  "detections": [...]            // Array of car detection results
}
```

| Field | Type | Description |
|-------|------|-------------|
| `source` | string | Filename of the source image |
| `image_dimensions.width` | integer | Image width in pixels |
| `image_dimensions.height` | integer | Image height in pixels |
| `total_cars` | integer | Total number of cars detected in the image |
| `detections` | array | Array of detection objects, one per car |

---

## Detection Object (per car)

Each item in the `detections` array represents one detected car and its wheels:

```json
{
  "car_id": 0,                    // Unique ID for this car in the image
  "car": {...},                   // Car bounding box and confidence
  "wheels": [...],                // Array of detected wheels
  "wheel_count": 2,               // Number of wheels detected
  "wheel_positions": {...},       // Front/rear wheel identification
  "rear_wheel_transform": {...},  // 3D transform for rear wheel (PRIMARY)
  "front_wheel_transform": {...}, // 3D transform for front wheel
  "car_geometry": {...}           // Overall car geometry info
}
```

---

## Bounding Box (`bbox`)

All bounding boxes share this structure:

```json
{
  "x1": 460,      // Left edge (pixels)
  "y1": 267,      // Top edge (pixels)
  "x2": 525,      // Right edge (pixels)
  "y2": 338,      // Bottom edge (pixels)
  "width": 65,    // Box width (x2 - x1)
  "height": 71    // Box height (y2 - y1)
}
```

| Field | Type | Description |
|-------|------|-------------|
| `x1` | integer | Left edge X coordinate in pixels |
| `y1` | integer | Top edge Y coordinate in pixels |
| `x2` | integer | Right edge X coordinate in pixels |
| `y2` | integer | Bottom edge Y coordinate in pixels |
| `width` | integer | Width of bounding box in pixels |
| `height` | integer | Height of bounding box in pixels |

---

## Wheel Transform (for Three.js integration)

The `rear_wheel_transform` and `front_wheel_transform` objects contain all data needed to position and orient a 3D asset on the wheel. **Use `rear_wheel_transform` as the primary target for overlay.**

### Position

```json
"position": {
  "x": 0.539,           // Normalized X [-1, 1], center of image = 0
  "y": -0.260,          // Normalized Y [-1, 1], center = 0, positive = up
  "z": -0.378,          // Estimated depth (relative, not absolute)
  "pixel_x": 492.5,     // Center X in image pixels
  "pixel_y": 302.5      // Center Y in image pixels
}
```

| Field | Type | Description |
|-------|------|-------------|
| `x` | float | Normalized X position. Range [-1, 1]. -1 = left edge, +1 = right edge |
| `y` | float | Normalized Y position. Range [-1, 1]. -1 = bottom, +1 = top |
| `z` | float | Estimated depth. Larger = closer to camera. Based on wheel size |
| `pixel_x` | float | Wheel center X coordinate in pixels |
| `pixel_y` | float | Wheel center Y coordinate in pixels |

**Three.js Usage:**
```javascript
mesh.position.set(transform.position.x, transform.position.y, transform.position.z);
```

---

### Rotation

The rotation data provides multiple representations for flexibility:

#### Quaternion (Recommended for Three.js)

```json
"quaternion": {
  "x": 0.0367,
  "y": 0.6697,
  "z": -0.0406,
  "w": 0.7406
}
```

**Three.js Usage:**
```javascript
mesh.quaternion.set(q.x, q.y, q.z, q.w);
```

#### Euler Angles

```json
"euler_angles": {
  "x": 0.0,             // Rotation around X-axis (radians)
  "y": 1.470,           // Rotation around Y-axis (radians)
  "z": -0.109,          // Rotation around Z-axis (radians)
  "order": "XYZ"        // Rotation order
}
```

**Three.js Usage:**
```javascript
mesh.rotation.set(euler.x, euler.y, euler.z, euler.order);
```

#### Rotation Matrix (3x3)

The rotation matrix columns represent the transformed basis vectors:

```json
"rotation_matrix": [
  [0.0997, 0.1093, 0.9889],   // Column 1: transformed X-axis
  [-0.0109, 0.9940, -0.1088], // Column 2: transformed Y-axis  
  [-0.9949, 0.0, 0.1003]      // Column 3: transformed Z-axis
]
```

**Note:** This is a column-major matrix. Each column is a basis vector.

#### Basis Vectors (Explicit)

```json
"basis_vectors": {
  "x_axis": [0.0997, -0.0109, -0.9949],  // Axle direction (into wheel)
  "y_axis": [0.1093, 0.9940, 0.0],        // Up direction
  "z_axis": [0.9889, -0.1088, 0.1003]     // Forward direction (tangent)
}
```

| Axis | Description | Points toward |
|------|-------------|---------------|
| `x_axis` | Wheel axle direction | Into the car (perpendicular to wheel face) |
| `y_axis` | Up direction | World up, adjusted for ground tilt |
| `z_axis` | Forward direction | Car's direction of travel (tangent to wheel) |

---

### Scale

```json
"scale": {
  "uniform": 0.242,       // Scale factor for 3D asset
  "radius_pixels": 34.0   // Detected wheel radius in pixels
}
```

| Field | Type | Description |
|-------|------|-------------|
| `uniform` | float | Recommended uniform scale factor for 3D asset |
| `radius_pixels` | float | Wheel radius in pixels (average of width/height รท 2) |

**Three.js Usage:**
```javascript
mesh.scale.setScalar(transform.scale.uniform);
```

---

### Rotation Metadata

```json
"metadata": {
  "viewing_angle_rad": 0.414,      // Wheel viewing angle (radians)
  "viewing_angle_deg": 23.72,      // Wheel viewing angle (degrees)
  "ground_angle_rad": -0.109,      // Ground tilt angle (radians)
  "ground_angle_deg": -6.27,       // Ground tilt angle (degrees)
  "car_direction_2d": [-0.996, 0.085], // Car direction vector (2D, normalized)
  "viewing_side": "left",          // Which side of car we're viewing
  "target_wheel": "rear"           // Which wheel this transform is for
}
```

| Field | Type | Description |
|-------|------|-------------|
| `viewing_angle_rad` | float | Angle at which we're viewing the wheel face. 0 = straight-on, ฯ/2 = pure side view |
| `viewing_angle_deg` | float | Same as above in degrees |
| `ground_angle_rad` | float | Tilt of ground plane. 0 = level, positive = tilted right |
| `ground_angle_deg` | float | Same as above in degrees |
| `car_direction_2d` | [float, float] | Normalized 2D vector indicating car's forward direction in image |
| `viewing_side` | string | `"left"` or `"right"` - which side of the car is visible |
| `target_wheel` | string | `"front"` or `"rear"` |

---

## Car Geometry

Overall geometry information for the detected car:

```json
"car_geometry": {
  "direction_2d": [-0.996, 0.085],  // Car facing direction (normalized)
  "ground_angle_deg": -6.27,        // Ground tilt in degrees
  "viewing_side": "left"            // Which side is visible
}
```

---

## Complete Three.js Integration Example

```javascript
// Parse API response
const detection = response.detections[0];
const transform = detection.rear_wheel_transform;

// Create your 3D wheel overlay mesh
const mesh = new THREE.Mesh(geometry, material);

// Apply position (normalized coordinates)
mesh.position.set(
  transform.position.x,
  transform.position.y,
  transform.position.z
);

// Apply rotation via quaternion (most reliable)
const q = transform.rotation.quaternion;
mesh.quaternion.set(q.x, q.y, q.z, q.w);

// Apply scale
mesh.scale.setScalar(transform.scale.uniform);

// Add to scene
scene.add(mesh);
```

---

## Assumptions & Limitations

1. **Side-view assumption**: The algorithm assumes most images show cars from a side angle
2. **Two visible wheels**: Only the two wheels on the visible side of the car are detected; the far-side wheels are assumed hidden
3. **Flat ground**: Ground plane is estimated from wheel positions but assumes relatively flat terrain
4. **Depth estimation**: Z-coordinate is estimated from wheel size (larger wheel = closer), not true depth
5. **Front/rear identification**: Based on wheel X-position relative to car bounding box; may be incorrect for unusual camera angles

---

## Null Values

If a wheel is not detected, the corresponding transform will be `null`:

```json
"rear_wheel_transform": null,
"front_wheel_transform": null
```

Always check for `null` before accessing transform properties.
